# –†–£–ö–û–í–û–î–°–¢–í–û –ü–û –£–õ–£–ß–®–ï–ù–ò–Ø–ú –ú–û–î–ï–õ–ò –û–¢–¢–û–ö–ê

## –û–±–∑–æ—Ä

–î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —É–ª—É—á—à–µ–Ω–∏–π, –≤–Ω–µ—Å–µ–Ω–Ω—ã—Ö –≤ –º–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤.

### –§–∞–π–ª—ã:
- **Churn_Model_Complete.ipynb** - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
- **Churn_Model_Enhanced_v2.ipynb** - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –±–∞–∑–æ–≤—ã–º–∏ –¥–æ—Ä–∞–±–æ—Ç–∫–∞–º–∏

---

## –ß–¢–û –£–ñ–ï –°–î–ï–õ–ê–ù–û

### ‚úÖ 1. –£–¥–∞–ª–µ–Ω–∏–µ segment_group –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º, –ø—Ä–∏–∑–Ω–∞–∫ `segment_group` —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–æ–π –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –∏ –Ω–µ –Ω–µ—Å–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

**–†–µ—à–µ–Ω–∏–µ:** –£–¥–∞–ª–∏–ª–∏ `segment_group` –∏–∑ `CATEGORICAL_FEATURES` –∏ –∏–∑ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤ –ø–æ—Å–ª–µ split.

**–ö–æ–¥ (—É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ Churn_Model_Enhanced_v2.ipynb):**
```python
# –í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
CATEGORICAL_FEATURES = ['obs_month', 'obs_quarter']  # –£–ë–†–ê–õ–ò segment_group!

# –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
if config.SEGMENT_COLUMN in seg1_train.columns:
    seg1_train = seg1_train.drop(columns=[config.SEGMENT_COLUMN])
    seg1_val = seg1_val.drop(columns=[config.SEGMENT_COLUMN])
    seg1_test = seg1_test.drop(columns=[config.SEGMENT_COLUMN])
```

### ‚úÖ 2. –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º

**–ó–∞—á–µ–º:** –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–∞ (—Ä–∞–∑–¥–µ–ª 3.5.4). –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

**–ß—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ:**
- –†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤—Å–µ—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¢–û–ü-20 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –§–∞–π–ª `output/feature_target_correlations.csv` –∏ –≥—Ä–∞—Ñ–∏–∫ `figures/01a_correlation_with_target.png`

### ‚úÖ 3. Helper Functions

–î–æ–±–∞–≤–ª–µ–Ω—ã –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- `calculate_psi()` - –¥–ª—è PSI –∞–Ω–∞–ª–∏–∑–∞
- `calculate_decile_table()` - –¥–ª—è –º–µ—Ç—Ä–∏–∫ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º
- `prepare_data_for_catboost()` - –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è CatBoost
- `prepare_data_for_xgboost_lightgbm()` - –¥–ª—è XGBoost/LightGBM
- `find_optimal_threshold()` - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
- `calculate_all_metrics()` - –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏

---

## –ß–¢–û –ù–£–ñ–ù–û –î–û–ë–ê–í–ò–¢–¨

### üîÑ 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π: XGBoost –∏ LightGBM

**–ó–∞—á–µ–º:** –†–∞–∑–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–æ–≥—É—Ç –ø–æ–∫–∞–∑–∞—Ç—å –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

**–ö–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è CatBoost:**

```python
# ====================================================================================
# –ú–û–î–ï–õ–¨ 1: –°–†–ê–í–ù–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í (CatBoost, XGBoost, LightGBM)
# ====================================================================================

print("\\n" + "="*80)
print("–°–†–ê–í–ù–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í –î–õ–Ø –ú–û–î–ï–õ–ò 1")
print("="*80)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
X_train_cb, y_train_1, cat_idx_1 = prepare_data_for_catboost(
    seg1_train, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)
X_val_cb, y_val_1, _ = prepare_data_for_catboost(
    seg1_val, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)
X_test_cb, y_test_1, _ = prepare_data_for_catboost(
    seg1_test, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)

# –î–ª—è XGBoost/LightGBM (label encoding)
X_train_xgb, _ = prepare_data_for_xgboost_lightgbm(
    seg1_train, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)
X_val_xgb, _ = prepare_data_for_xgboost_lightgbm(
    seg1_val, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)
X_test_xgb, _ = prepare_data_for_xgboost_lightgbm(
    seg1_test, config.CATEGORICAL_FEATURES,
    config.ID_COLUMNS + [config.TARGET_COLUMN]
)

# Class weights
weights_1, w0_1, w1_1 = calculate_class_weights(y_train_1)
scale_pos_weight = w1_1 / w0_1

# =============================================================================
# 1. CatBoost (—É–∂–µ –æ–±—É—á–µ–Ω–∞)
# =============================================================================
print("\\n1. CatBoost (–æ–±—É—á–µ–Ω–∞ —Ä–∞–Ω–µ–µ)")

# =============================================================================
# 2. XGBoost
# =============================================================================
print("\\n2. –û–±—É—á–µ–Ω–∏–µ XGBoost...")

model_xgb_1 = xgb.XGBClassifier(
    max_depth=4,
    learning_rate=0.05,
    n_estimators=500,
    objective='binary:logistic',
    eval_metric='auc',
    subsample=0.8,
    colsample_bytree=0.8,
    min_child_weight=100,
    scale_pos_weight=scale_pos_weight,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
    reg_alpha=0.1,
    reg_lambda=1,
    random_state=42,
    n_jobs=-1,
    early_stopping_rounds=100
)

model_xgb_1.fit(
    X_train_xgb, y_train_1,
    eval_set=[(X_val_xgb, y_val_1)],
    verbose=100
)

# Predictions
y_val_pred_proba_xgb = model_xgb_1.predict_proba(X_val_xgb)[:, 1]
y_test_pred_proba_xgb = model_xgb_1.predict_proba(X_test_xgb)[:, 1]

# Optimal threshold
optimal_threshold_xgb, _ = find_optimal_threshold(y_val_1, y_val_pred_proba_xgb, 'f1')
y_test_pred_xgb = (y_test_pred_proba_xgb >= optimal_threshold_xgb).astype(int)

# Metrics
test_metrics_xgb = calculate_all_metrics(y_test_1, y_test_pred_proba_xgb, y_test_pred_xgb,
                                         optimal_threshold_xgb, 'Test (OOT)')

print(f"\\n‚úì XGBoost –æ–±—É—á–µ–Ω")
print(f"  Test ROC-AUC: {test_metrics_xgb['roc_auc']:.4f}")
print(f"  Test GINI: {test_metrics_xgb['gini']:.4f}")
print(f"  Test F1: {test_metrics_xgb['f1']:.4f}")

# =============================================================================
# 3. LightGBM
# =============================================================================
print("\\n3. –û–±—É—á–µ–Ω–∏–µ LightGBM...")

model_lgb_1 = lgb.LGBMClassifier(
    max_depth=4,
    learning_rate=0.05,
    n_estimators=500,
    objective='binary',
    metric='auc',
    subsample=0.8,
    colsample_bytree=0.8,
    min_child_samples=100,
    scale_pos_weight=scale_pos_weight,
    reg_alpha=0.1,
    reg_lambda=1,
    random_state=42,
    n_jobs=-1,
    verbosity=-1
)

model_lgb_1.fit(
    X_train_xgb, y_train_1,
    eval_set=[(X_val_xgb, y_val_1)],
    eval_metric='auc',
    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)]
)

# Predictions
y_val_pred_proba_lgb = model_lgb_1.predict_proba(X_val_xgb)[:, 1]
y_test_pred_proba_lgb = model_lgb_1.predict_proba(X_test_xgb)[:, 1]

# Optimal threshold
optimal_threshold_lgb, _ = find_optimal_threshold(y_val_1, y_val_pred_proba_lgb, 'f1')
y_test_pred_lgb = (y_test_pred_proba_lgb >= optimal_threshold_lgb).astype(int)

# Metrics
test_metrics_lgb = calculate_all_metrics(y_test_1, y_test_pred_proba_lgb, y_test_pred_lgb,
                                         optimal_threshold_lgb, 'Test (OOT)')

print(f"\\n‚úì LightGBM –æ–±—É—á–µ–Ω")
print(f"  Test ROC-AUC: {test_metrics_lgb['roc_auc']:.4f}")
print(f"  Test GINI: {test_metrics_lgb['gini']:.4f}")
print(f"  Test F1: {test_metrics_lgb['f1']:.4f}")

# =============================================================================
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
# =============================================================================
print("\\n" + "="*80)
print("–°–†–ê–í–ù–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í (Test OOT)")
print("="*80)

comparison_algorithms = pd.DataFrame([
    {
        'Algorithm': 'CatBoost',
        'ROC-AUC': test_metrics_1['roc_auc'],
        'GINI': test_metrics_1['gini'],
        'F1': test_metrics_1['f1'],
        'Precision': test_metrics_1['precision'],
        'Recall': test_metrics_1['recall']
    },
    {
        'Algorithm': 'XGBoost',
        'ROC-AUC': test_metrics_xgb['roc_auc'],
        'GINI': test_metrics_xgb['gini'],
        'F1': test_metrics_xgb['f1'],
        'Precision': test_metrics_xgb['precision'],
        'Recall': test_metrics_xgb['recall']
    },
    {
        'Algorithm': 'LightGBM',
        'ROC-AUC': test_metrics_lgb['roc_auc'],
        'GINI': test_metrics_lgb['gini'],
        'F1': test_metrics_lgb['f1'],
        'Precision': test_metrics_lgb['precision'],
        'Recall': test_metrics_lgb['recall']
    }
])

print(comparison_algorithms.to_string(index=False))

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
comparison_algorithms.to_csv(config.OUTPUT_DIR / 'algorithm_comparison_model1.csv', index=False)
print("\\n‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: output/algorithm_comparison_model1.csv")
```

**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:**
- **CatBoost:** –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –Ω–∞—Ç–∏–≤–Ω–æ
- **XGBoost:** –ë—ã—Å—Ç—Ä, —á–∞—Å—Ç–æ –¥–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ç—Ä–µ–±—É–µ—Ç label encoding –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
- **LightGBM:** –û—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–π, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –í—Å–µ —Ç—Ä–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç `scale_pos_weight` –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤

---

### üîÑ 5. PSI (Population Stability Index)

**–ó–∞—á–µ–º:** –¢—Ä–µ–±—É–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–∞ (—Ä–∞–∑–¥–µ–ª 3.5.4). –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ–∂–¥—É train –∏ test.

**–ö–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ü–û–°–õ–ï preprocessing:**

```python
# ====================================================================================
# PSI ANALYSIS
# ====================================================================================

print("\\n" + "="*80)
print("PSI (POPULATION STABILITY INDEX) ANALYSIS")
print("="*80)

print("\\n–†–∞—Å—á–µ—Ç PSI –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö...")
print("PSI < 0.1: –ù–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")
print("0.1 <= PSI < 0.2: –£–º–µ—Ä–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è")
print("PSI >= 0.2: –ó–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –º–æ–¥–µ–ª–∏)\\n")

# –í—ã–±—Ä–∞—Ç—å —Ç–æ–ø-20 –≤–∞–∂–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
numeric_features = [c for c in pipeline.final_features
                   if c not in config.CATEGORICAL_FEATURES]

# –†–∞—Å—á–µ—Ç PSI –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
psi_results = []
for feature in numeric_features[:50]:  # —Ç–æ–ø-50 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    if feature in train_processed.columns and feature in test_processed.columns:
        try:
            psi_value = calculate_psi(
                train_processed[feature].values,
                test_processed[feature].values,
                buckets=10
            )
            psi_results.append({
                'feature': feature,
                'psi': psi_value,
                'status': 'OK' if psi_value < 0.1 else ('WARNING' if psi_value < 0.2 else 'CRITICAL')
            })
        except:
            pass

psi_df = pd.DataFrame(psi_results).sort_values('psi', ascending=False)

print("\\n–¢–û–ü-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ PSI:")
print(psi_df.head(20).to_string(index=False))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, ax = plt.subplots(figsize=(12, 8))
colors = psi_df.head(20)['status'].map({'OK': 'green', 'WARNING': 'orange', 'CRITICAL': 'red'})
ax.barh(range(len(psi_df.head(20))), psi_df.head(20)['psi'].values, color=colors, alpha=0.7)
ax.set_yticks(range(len(psi_df.head(20))))
ax.set_yticklabels(psi_df.head(20)['feature'].values, fontsize=9)
ax.set_xlabel('PSI Value')
ax.set_title('Population Stability Index (PSI) - Top 20', fontweight='bold')
ax.axvline(0.1, color='orange', linestyle='--', label='Warning threshold')
ax.axvline(0.2, color='red', linestyle='--', label='Critical threshold')
ax.legend()
ax.invert_yaxis()
plt.tight_layout()
plt.savefig(config.FIGURES_DIR / '03_psi_analysis.png', dpi=150, bbox_inches='tight')
plt.show()

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
psi_df.to_csv(config.OUTPUT_DIR / 'psi_analysis.csv', index=False)
print("\\n‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: output/psi_analysis.csv")
print("‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: figures/03_psi_analysis.png")

# Summary
critical_count = len(psi_df[psi_df['status'] == 'CRITICAL'])
warning_count = len(psi_df[psi_df['status'] == 'WARNING'])
ok_count = len(psi_df[psi_df['status'] == 'OK'])

print(f"\\n–°–≤–æ–¥–∫–∞ PSI:")
print(f"  OK (< 0.1): {ok_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print(f"  WARNING (0.1-0.2): {warning_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print(f"  CRITICAL (>= 0.2): {critical_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

if critical_count > 0:
    print(f"\\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {critical_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º PSI!")
    print("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    print(psi_df[psi_df['status'] == 'CRITICAL']['feature'].tolist())

print("="*80)
```

---

### üîÑ 6. –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º (Decile Analysis + Lift)

**–ó–∞—á–µ–º:** –¢—Ä–µ–±—É–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–∞ (—Ä–∞–∑–¥–µ–ª 5.4). –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤.

**–ö–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ü–û–°–õ–ï –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏:**

```python
# ====================================================================================
# DECILE ANALYSIS & LIFT TABLE
# ====================================================================================

print("\\n" + "="*80)
print("DECILE ANALYSIS & LIFT (Test OOT)")
print("="*80)

# –†–∞—Å—á–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –ø–æ –¥–µ—Ü–∏–ª—è–º
decile_table = calculate_decile_table(y_test_1, y_test_pred_proba_1, n_deciles=10)

print("\\n–¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º (deciles):")
print(decile_table.to_string(index=False))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. Churn Rate –ø–æ –¥–µ—Ü–∏–ª—è–º
ax = axes[0, 0]
ax.bar(decile_table['percentile'], decile_table['target_rate'] * 100,
       color='steelblue', alpha=0.7, edgecolor='black')
ax.set_xlabel('Decile (1=highest risk)')
ax.set_ylabel('Churn Rate (%)')
ax.set_title('Churn Rate –ø–æ –¥–µ—Ü–∏–ª—è–º', fontweight='bold')
ax.set_xticks(decile_table['percentile'])
for i, v in enumerate(decile_table['target_rate'] * 100):
    ax.text(decile_table['percentile'].iloc[i], v, f'{v:.2f}%',
           ha='center', va='bottom', fontsize=9)

# 2. Lift
ax = axes[0, 1]
ax.bar(decile_table['percentile'], decile_table['lift'],
       color='green', alpha=0.7, edgecolor='black')
ax.axhline(1.0, color='red', linestyle='--', label='Baseline')
ax.set_xlabel('Decile (1=highest risk)')
ax.set_ylabel('Lift')
ax.set_title('Lift –ø–æ –¥–µ—Ü–∏–ª—è–º', fontweight='bold')
ax.set_xticks(decile_table['percentile'])
ax.legend()
for i, v in enumerate(decile_table['lift']):
    ax.text(decile_table['percentile'].iloc[i], v, f'{v:.2f}',
           ha='center', va='bottom', fontsize=9)

# 3. Cumulative Precision
ax = axes[1, 0]
ax.plot(decile_table['percentile'], decile_table['precision_cum'] * 100,
       marker='o', color='purple', linewidth=2, markersize=8)
ax.set_xlabel('Decile (1=highest risk)')
ax.set_ylabel('Cumulative Precision (%)')
ax.set_title('Cumulative Precision', fontweight='bold')
ax.set_xticks(decile_table['percentile'])
ax.grid(alpha=0.3)

# 4. Cumulative Recall
ax = axes[1, 1]
ax.plot(decile_table['percentile'], decile_table['recall_cum'] * 100,
       marker='o', color='orange', linewidth=2, markersize=8)
ax.set_xlabel('Decile (1=highest risk)')
ax.set_ylabel('Cumulative Recall (%)')
ax.set_title('Cumulative Recall', fontweight='bold')
ax.set_xticks(decile_table['percentile'])
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig(config.FIGURES_DIR / '04_decile_analysis_model1.png', dpi=150, bbox_inches='tight')
plt.show()

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
decile_table.to_csv(config.OUTPUT_DIR / 'decile_analysis_model1.csv', index=False)
print("\\n‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: output/decile_analysis_model1.csv")
print("‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: figures/04_decile_analysis_model1.png")

print(f"\\n–ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:")
print(f"  Top 10% –∫–ª–∏–µ–Ω—Ç–æ–≤ (decile 1):")
print(f"    Churn Rate: {decile_table.iloc[0]['target_rate']*100:.2f}%")
print(f"    Lift: {decile_table.iloc[0]['lift']:.2f}x")
print(f"  Top 30% –∫–ª–∏–µ–Ω—Ç–æ–≤ (deciles 1-3):")
print(f"    Cumulative Recall: {decile_table.iloc[2]['recall_cum']*100:.2f}%")
print(f"    Cumulative Precision: {decile_table.iloc[2]['precision_cum']*100:.2f}%")

print("="*80)
```

**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫:**
- **Percentile/Decile:** –ì—Ä—É–ø–ø—ã –∫–ª–∏–µ–Ω—Ç–æ–≤, 1 = —Å–∞–º—ã–µ —Ä–∏—Å–∫–æ–≤—ã–µ (highest probability)
- **Target Rate:** –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç—Ç–æ–∫–∞ –≤ –∫–∞–∂–¥–æ–º –¥–µ—Ü–ø–ª–µ
- **Lift:** –í–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ target rate –≤ –≥—Ä—É–ø–ø–µ –≤—ã—à–µ –±–∞–∑–æ–≤–æ–≥–æ (>1 = —Ö–æ—Ä–æ—à–æ)
- **Precision (cum):** –¢–æ—á–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–∞–∫ churn –¥–æ —ç—Ç–æ–≥–æ –¥–µ—Ü–∏–ª—è
- **Recall (cum):** –ö–∞–∫–æ–π % –≤—Å–µ—Ö churn –º—ã –ø–æ–π–º–∞–ª–∏ –¥–æ —ç—Ç–æ–≥–æ –¥–µ—Ü–∏–ª—è

---

### üîÑ 7. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (Undersampling, SMOTE)

**–ó–∞—á–µ–º:** –£ –≤–∞—Å —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (1:65 –¥–ª—è –º–æ–¥–µ–ª–∏ 1, 1:200 –¥–ª—è –º–æ–¥–µ–ª–∏ 2). Class weights –ø–æ–º–æ–≥–∞—é—Ç, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å F1.

**–ö–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ö–ê–ö –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢:**

```python
# ====================================================================================
# –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –° –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–û–ô –ö–õ–ê–°–°–û–í
# ====================================================================================

print("\\n" + "="*80)
print("–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´: –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –ö–õ–ê–°–°–û–í")
print("="*80)

print("\\n–¢–µ—Å—Ç–∏—Ä—É–µ–º 4 –ø–æ–¥—Ö–æ–¥–∞:")
print("  1. Baseline (Class Weights) - —É–∂–µ –æ–±—É—á–µ–Ω–æ")
print("  2. Random Undersampling")
print("  3. SMOTE (Oversampling)")
print("  4. Hybrid (SMOTE + Undersampling)")

# Baseline - —É–∂–µ –µ—Å—Ç—å
print(f"\\n1. BASELINE (Class Weights):")
print(f"   Test F1: {test_metrics_1['f1']:.4f}")
print(f"   Test Recall: {test_metrics_1['recall']:.4f}")
print(f"   Test Precision: {test_metrics_1['precision']:.4f}")

# =============================================================================
# 2. Random Undersampling
# =============================================================================
print("\\n2. RANDOM UNDERSAMPLING...")

rus = RandomUnderSampler(random_state=42, sampling_strategy=0.3)  # 1:3 ratio
X_train_rus, y_train_rus = rus.fit_resample(X_train_1, y_train_1)

print(f"   –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ undersampling: {len(X_train_rus):,}")
print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {Counter(y_train_rus)}")

# –û–±—É—á–µ–Ω–∏–µ CatBoost –±–µ–∑ class weights (–¥–∞–Ω–Ω—ã–µ —É–∂–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã)
model_rus = CatBoostClassifier(
    **{k: v for k, v in config.CATBOOST_PARAMS.items()},
    verbose=0
)

pool_rus = Pool(X_train_rus, y_train_rus, cat_features=cat_idx_1)
model_rus.fit(pool_rus, eval_set=val_pool_1, plot=False)

# Eval
y_test_pred_proba_rus = model_rus.predict_proba(test_pool_1)[:, 1]
threshold_rus, _ = find_optimal_threshold(y_val_1,
                                         model_rus.predict_proba(val_pool_1)[:, 1], 'f1')
y_test_pred_rus = (y_test_pred_proba_rus >= threshold_rus).astype(int)
metrics_rus = calculate_all_metrics(y_test_1, y_test_pred_proba_rus, y_test_pred_rus,
                                   threshold_rus, 'Undersampling')

print(f"   Test F1: {metrics_rus['f1']:.4f}")
print(f"   Test Recall: {metrics_rus['recall']:.4f}")
print(f"   Test Precision: {metrics_rus['precision']:.4f}")

# =============================================================================
# 3. SMOTE
# =============================================================================
print("\\n3. SMOTE (Oversampling)...")

# SMOTE —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
# –í—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–∫–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
X_train_for_smote = X_train_1.copy()
for cat in config.CATEGORICAL_FEATURES:
    if cat in X_train_for_smote.columns:
        le = LabelEncoder()
        X_train_for_smote[cat] = le.fit_transform(X_train_for_smote[cat])

smote = SMOTE(random_state=42, sampling_strategy=0.3)
X_train_smote, y_train_smote = smote.fit_resample(X_train_for_smote, y_train_1)

# –û–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è CatBoost
X_train_smote_cb = X_train_smote.copy()
for cat in config.CATEGORICAL_FEATURES:
    if cat in X_train_smote_cb.columns:
        X_train_smote_cb[cat] = X_train_smote_cb[cat].astype(str)

print(f"   –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ SMOTE: {len(X_train_smote):,}")
print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {Counter(y_train_smote)}")

# –û–±—É—á–µ–Ω–∏–µ
model_smote = CatBoostClassifier(
    **{k: v for k, v in config.CATBOOST_PARAMS.items()},
    verbose=0
)

pool_smote = Pool(X_train_smote_cb, y_train_smote, cat_features=cat_idx_1)
model_smote.fit(pool_smote, eval_set=val_pool_1, plot=False)

# Eval
y_test_pred_proba_smote = model_smote.predict_proba(test_pool_1)[:, 1]
threshold_smote, _ = find_optimal_threshold(y_val_1,
                                           model_smote.predict_proba(val_pool_1)[:, 1], 'f1')
y_test_pred_smote = (y_test_pred_proba_smote >= threshold_smote).astype(int)
metrics_smote = calculate_all_metrics(y_test_1, y_test_pred_proba_smote, y_test_pred_smote,
                                     threshold_smote, 'SMOTE')

print(f"   Test F1: {metrics_smote['f1']:.4f}")
print(f"   Test Recall: {metrics_smote['recall']:.4f}")
print(f"   Test Precision: {metrics_smote['precision']:.4f}")

# =============================================================================
# 4. Hybrid (SMOTE + Undersampling)
# =============================================================================
print("\\n4. HYBRID (SMOTE minority + Undersample majority)...")

# –°–Ω–∞—á–∞–ª–∞ SMOTE
smote_hybrid = SMOTE(random_state=42, sampling_strategy=0.15)
X_temp, y_temp = smote_hybrid.fit_resample(X_train_for_smote, y_train_1)

# –ü–æ—Ç–æ–º Undersampling
rus_hybrid = RandomUnderSampler(random_state=42, sampling_strategy=0.5)
X_train_hybrid, y_train_hybrid = rus_hybrid.fit_resample(X_temp, y_temp)

# –û–±—Ä–∞—Ç–Ω–æ –¥–ª—è CatBoost
X_train_hybrid_cb = X_train_hybrid.copy()
for cat in config.CATEGORICAL_FEATURES:
    if cat in X_train_hybrid_cb.columns:
        X_train_hybrid_cb[cat] = X_train_hybrid_cb[cat].astype(str)

print(f"   –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ hybrid: {len(X_train_hybrid):,}")
print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {Counter(y_train_hybrid)}")

# –û–±—É—á–µ–Ω–∏–µ
model_hybrid = CatBoostClassifier(
    **{k: v for k, v in config.CATBOOST_PARAMS.items()},
    verbose=0
)

pool_hybrid = Pool(X_train_hybrid_cb, y_train_hybrid, cat_features=cat_idx_1)
model_hybrid.fit(pool_hybrid, eval_set=val_pool_1, plot=False)

# Eval
y_test_pred_proba_hybrid = model_hybrid.predict_proba(test_pool_1)[:, 1]
threshold_hybrid, _ = find_optimal_threshold(y_val_1,
                                            model_hybrid.predict_proba(val_pool_1)[:, 1], 'f1')
y_test_pred_hybrid = (y_test_pred_proba_hybrid >= threshold_hybrid).astype(int)
metrics_hybrid = calculate_all_metrics(y_test_1, y_test_pred_proba_hybrid, y_test_pred_hybrid,
                                      threshold_hybrid, 'Hybrid')

print(f"   Test F1: {metrics_hybrid['f1']:.4f}")
print(f"   Test Recall: {metrics_hybrid['recall']:.4f}")
print(f"   Test Precision: {metrics_hybrid['precision']:.4f}")

# =============================================================================
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
# =============================================================================
print("\\n" + "="*80)
print("–°–†–ê–í–ù–ï–ù–ò–ï –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ò (Test OOT)")
print("="*80)

balancing_comparison = pd.DataFrame([
    {
        'Method': 'Baseline (Class Weights)',
        'F1': test_metrics_1['f1'],
        'Precision': test_metrics_1['precision'],
        'Recall': test_metrics_1['recall'],
        'ROC-AUC': test_metrics_1['roc_auc']
    },
    {
        'Method': 'Random Undersampling',
        'F1': metrics_rus['f1'],
        'Precision': metrics_rus['precision'],
        'Recall': metrics_rus['recall'],
        'ROC-AUC': metrics_rus['roc_auc']
    },
    {
        'Method': 'SMOTE',
        'F1': metrics_smote['f1'],
        'Precision': metrics_smote['precision'],
        'Recall': metrics_smote['recall'],
        'ROC-AUC': metrics_smote['roc_auc']
    },
    {
        'Method': 'Hybrid (SMOTE+Under)',
        'F1': metrics_hybrid['f1'],
        'Precision': metrics_hybrid['precision'],
        'Recall': metrics_hybrid['recall'],
        'ROC-AUC': metrics_hybrid['roc_auc']
    }
])

print(balancing_comparison.to_string(index=False))

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
balancing_comparison.to_csv(config.OUTPUT_DIR / 'balancing_comparison_model1.csv', index=False)
print("\\n‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: output/balancing_comparison_model1.csv")

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
best_method = balancing_comparison.loc[balancing_comparison['F1'].idxmax(), 'Method']
print(f"\\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –õ—É—á—à–∏–π F1 –ø–æ–∫–∞–∑–∞–ª –º–µ—Ç–æ–¥ '{best_method}'")

print("="*80)
```

**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:**
- **Class Weights:** –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
- **Undersampling:** –£–¥–∞–ª—è–µ—Ç —á–∞—Å—Ç—å –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∞ (–±—ã—Å—Ç—Ä–æ, –Ω–æ —Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ)
- **SMOTE:** –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤–∞ (–Ω–µ —Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ, –Ω–æ –º–æ–∂–µ—Ç overfitting)
- **Hybrid:** –ö–æ–º–±–∏–Ω–∞—Ü–∏—è (–±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ø–æ—Ç–µ—Ä–µ–π –¥–∞–Ω–Ω—ã—Ö –∏ overfitting)

---

## –ò–¢–û–ì–û–í–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ù–û–£–¢–ë–£–ö–ê

1. ‚úÖ –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ (–¥–æ–±–∞–≤–ª–µ–Ω—ã xgboost, lightgbm, imblearn)
2. ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (segment_group —É–¥–∞–ª–µ–Ω –∏–∑ CATEGORICAL_FEATURES)
3. ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
4. ‚úÖ EDA
5. ‚úÖ **–ù–û–í–û–ï:** –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º
6. ‚úÖ Temporal Split
7. ‚úÖ Gap Removal
8. ‚úÖ Preprocessing
9. ‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º + —É–¥–∞–ª–µ–Ω–∏–µ segment_group
10. ‚úÖ **–ù–û–í–û–ï:** Helper Functions
11. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** –ú–æ–¥–µ–ª—å 1 - CatBoost (–µ—Å—Ç—å)
12. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** –ú–æ–¥–µ–ª—å 1 - XGBoost
13. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** –ú–æ–¥–µ–ª—å 1 - LightGBM
14. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
15. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** PSI Analysis
16. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** Decile Analysis –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
17. üîÑ **–î–û–ë–ê–í–ò–¢–¨:** –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
18. üîÑ –ü–æ–≤—Ç–æ—Ä–∏—Ç—å 11-17 –¥–ª—è –ú–æ–¥–µ–ª–∏ 2
19. üîÑ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
20. üîÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π

---

## –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

### –î–ª—è –ú–æ–¥–µ–ª–∏ 1 (Small Business):
- ‚úÖ –¢–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ (GINI 0.78, ROC-AUC 0.89)
- üéØ F1 –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é SMOTE –∏–ª–∏ Hybrid –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
- üéØ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å XGBoost - —á–∞—Å—Ç–æ –¥–∞–µ—Ç –ª—É—á—à–∏–π F1

### –î–ª—è –ú–æ–¥–µ–ª–∏ 2 (Middle + Large Business):
- ‚ö†Ô∏è F1 –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π (0.1157) –∏–∑-–∑–∞ —Å–∏–ª—å–Ω–æ–≥–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ 1:200
- üéØ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å SMOTE –∏–ª–∏ Hybrid
- üéØ –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å focal loss –≤ CatBoost
- üéØ –í–æ–∑–º–æ–∂–Ω–æ, –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å –ú–æ–¥–µ–ª—å—é 1 –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å transfer learning

### –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–∞:
- ‚úÖ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ç–∞—Ä–≥–µ—Ç–æ–º - –≥–æ—Ç–æ–≤–∞
- üîÑ PSI - –¥–æ–±–∞–≤–∏—Ç—å
- üîÑ Decile/Lift analysis - –¥–æ–±–∞–≤–∏—Ç—å
- üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ - –¥–æ–±–∞–≤–∏—Ç—å

---

## –§–ê–ô–õ–´ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —É–ª—É—á—à–µ–Ω–∏–π —É –≤–∞—Å –±—É–¥—É—Ç:

### CSV —Ñ–∞–π–ª—ã (output/):
- `feature_target_correlations.csv` - –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º
- `psi_analysis.csv` - PSI –¥–ª—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- `decile_analysis_model1.csv` - –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º
- `decile_analysis_model2.csv`
- `algorithm_comparison_model1.csv` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ CatBoost/XGBoost/LightGBM
- `algorithm_comparison_model2.csv`
- `balancing_comparison_model1.csv` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
- `balancing_comparison_model2.csv`
- `models_comparison.csv` - –∏—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

### –ì—Ä–∞—Ñ–∏–∫–∏ (figures/):
- `01_eda_target.png` - EDA —Ç–∞—Ä–≥–µ—Ç–∞
- `01a_correlation_with_target.png` - –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
- `02_models_comparison.png` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- `03_psi_analysis.png` - PSI
- `04_decile_analysis_model1.png` - decile/lift
- `04_decile_analysis_model2.png`
- `05_balancing_comparison.png` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏

### –ú–æ–¥–µ–ª–∏ (models/):
- –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

---

## –ö–ê–ö –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨

1. **–û—Ç–∫—Ä–æ–π—Ç–µ `Churn_Model_Enhanced_v2.ipynb`** - –±–∞–∑–æ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è —É–∂–µ –µ—Å—Ç—å
2. **–ö–æ–ø–∏—Ä—É–π—Ç–µ –∫–æ–¥ –∏–∑ —ç—Ç–æ–≥–æ README** —Å–µ–∫—Ü–∏—è–º–∏ 4-7 –≤ –Ω—É–∂–Ω—ã–µ –º–µ—Å—Ç–∞ –Ω–æ—É—Ç–±—É–∫–∞
3. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–µ—Å—å –Ω–æ—É—Ç–±—É–∫** –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
4. **–í—ã–±–µ—Ä–∏—Ç–µ –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
5. **–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é** –±–∞–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑—É—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

---

## –ö–û–ù–¢–†–û–õ–¨–ù–´–ô –°–ü–ò–°–û–ö

- [x] segment_group —É–¥–∞–ª–µ–Ω –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- [x] –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω
- [x] segment_group —É–¥–∞–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ split
- [x] Helper functions –¥–æ–±–∞–≤–ª–µ–Ω—ã
- [ ] XGBoost –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] LightGBM –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] PSI –∞–Ω–∞–ª–∏–∑ –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] Decile analysis –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∞

---

**–£–¥–∞—á–∏ —Å —É–ª—É—á—à–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏! üöÄ**
