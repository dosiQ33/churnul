#!/usr/bin/env python3
"""
Скрипт для добавления остальных ячеек в Churn_Model_Enhanced.ipynb
"""

import json
from pathlib import Path

# Читаем существующий ноутбук
notebook_path = Path("Churn_Model_Enhanced.ipynb")
with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Новые ячейки для добавления
new_cells = [
    # Helper functions
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": ["---\n", "# 9. НОВОЕ: ФУНКЦИИ ДЛЯ PSI И МЕТРИК ПО ПЕРЦЕНТИЛЯМ"]
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# ====================================================================================\n",
            "# HELPER FUNCTIONS\n",
            "# ====================================================================================\n",
            "\n",
            "def calculate_psi(expected, actual, buckets=10):\n",
            "    \"\"\"\n",
            "    Calculate Population Stability Index (PSI)\n",
            "    \n",
            "    PSI < 0.1: No significant change\n",
            "    0.1 <= PSI < 0.2: Moderate change\n",
            "    PSI >= 0.2: Significant change (требуется пересмотр модели)\n",
            "    \"\"\"\n",
            "    breakpoints = np.arange(0, buckets + 1) / buckets * 100\n",
            "    breakpoints = np.percentile(expected, breakpoints)\n",
            "    breakpoints[0] = -np.inf\n",
            "    breakpoints[-1] = np.inf\n",
            "    \n",
            "    expected_percents = pd.cut(expected, breakpoints, duplicates='drop').value_counts(normalize=True).sort_index()\n",
            "    actual_percents = pd.cut(actual, breakpoints, duplicates='drop').value_counts(normalize=True).sort_index()\n",
            "    \n",
            "    # Ensure same bins\n",
            "    expected_percents = expected_percents.reindex(actual_percents.index, fill_value=0.001)\n",
            "    actual_percents = actual_percents.reindex(expected_percents.index, fill_value=0.001)\n",
            "    \n",
            "    psi_value = np.sum((actual_percents - expected_percents) * np.log(actual_percents / expected_percents))\n",
            "    \n",
            "    return psi_value\n",
            "\n",
            "\n",
            "def calculate_decile_table(y_true, y_pred_proba, n_deciles=10):\n",
            "    \"\"\"\n",
            "    Создать таблицу метрик по децилям (перцентилям)\n",
            "    \n",
            "    Returns:\n",
            "    - DataFrame с колонками: percentile, count, target_count, target_rate, \n",
            "                           precision_cum, recall_cum, lift\n",
            "    \"\"\"\n",
            "    df = pd.DataFrame({\n",
            "        'y_true': y_true,\n",
            "        'y_pred_proba': y_pred_proba\n",
            "    })\n",
            "    \n",
            "    # Сортировка по вероятности (от высокой к низкой)\n",
            "    df = df.sort_values('y_pred_proba', ascending=False).reset_index(drop=True)\n",
            "    \n",
            "    # Разбиение на децили\n",
            "    df['decile'] = pd.qcut(df['y_pred_proba'], q=n_deciles, labels=False, duplicates='drop') + 1\n",
            "    df['decile'] = n_deciles - df['decile'] + 1  # Reverse (1 = highest prob)\n",
            "    \n",
            "    # Агрегация по децилям\n",
            "    decile_table = df.groupby('decile').agg(\n",
            "        count=('y_true', 'size'),\n",
            "        target_count=('y_true', 'sum'),\n",
            "        min_prob=('y_pred_proba', 'min'),\n",
            "        max_prob=('y_pred_proba', 'max')\n",
            "    ).reset_index()\n",
            "    \n",
            "    decile_table['target_rate'] = decile_table['target_count'] / decile_table['count']\n",
            "    \n",
            "    # Cumulative\n",
            "    decile_table['count_cum'] = decile_table['count'].cumsum()\n",
            "    decile_table['target_count_cum'] = decile_table['target_count'].cumsum()\n",
            "    \n",
            "    # Precision (cumulative)\n",
            "    decile_table['precision_cum'] = decile_table['target_count_cum'] / decile_table['count_cum']\n",
            "    \n",
            "    # Recall (cumulative)\n",
            "    total_targets = df['y_true'].sum()\n",
            "    decile_table['recall_cum'] = decile_table['target_count_cum'] / total_targets\n",
            "    \n",
            "    # Lift\n",
            "    baseline_rate = total_targets / len(df)\n",
            "    decile_table['lift'] = decile_table['target_rate'] / baseline_rate\n",
            "    \n",
            "    # Rename\n",
            "    decile_table = decile_table.rename(columns={'decile': 'percentile'})\n",
            "    \n",
            "    return decile_table\n",
            "\n",
            "\n",
            "def prepare_data_for_model(df, categorical_features, exclude_cols, for_catboost=False):\n",
            "    \"\"\"\n",
            "    Подготовка данных для моделей\n",
            "    \n",
            "    for_catboost=True: вернет categorical indices для CatBoost\n",
            "    for_catboost=False: закодирует категориальные как числа для XGBoost/LightGBM\n",
            "    \"\"\"\n",
            "    feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
            "    \n",
            "    X = df[feature_cols].copy()\n",
            "    y = df[config.TARGET_COLUMN].copy() if config.TARGET_COLUMN in df.columns else None\n",
            "    \n",
            "    if for_catboost:\n",
            "        # Конвертация категориальных в string для CatBoost\n",
            "        for cat in categorical_features:\n",
            "            if cat in X.columns:\n",
            "                X[cat] = X[cat].astype(str).replace('nan', 'missing')\n",
            "        \n",
            "        # Индексы категориальных\n",
            "        cat_indices = [i for i, c in enumerate(feature_cols) if c in categorical_features]\n",
            "        return X, y, cat_indices\n",
            "    else:\n",
            "        # Label encoding для XGBoost/LightGBM\n",
            "        encoders = {}\n",
            "        for cat in categorical_features:\n",
            "            if cat in X.columns:\n",
            "                le = LabelEncoder()\n",
            "                X[cat] = le.fit_transform(X[cat].astype(str))\n",
            "                encoders[cat] = le\n",
            "        \n",
            "        return X, y, encoders\n",
            "\n",
            "\n",
            "def calculate_class_weights(y):\n",
            "    \"\"\"Расчет весов классов\"\"\"\n",
            "    n_samples = len(y)\n",
            "    n_classes = 2\n",
            "    n_class_0 = (y == 0).sum()\n",
            "    n_class_1 = (y == 1).sum()\n",
            "\n",
            "    weight_0 = n_samples / (n_classes * n_class_0)\n",
            "    weight_1 = n_samples / (n_classes * n_class_1)\n",
            "\n",
            "    weights = np.ones(len(y))\n",
            "    weights[y == 1] = weight_1\n",
            "    weights[y == 0] = weight_0\n",
            "\n",
            "    return weights, weight_0, weight_1\n",
            "\n",
            "\n",
            "def find_optimal_threshold(y_true, y_pred_proba, metric='f1'):\n",
            "    \"\"\"Поиск оптимального порога\"\"\"\n",
            "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
            "    scores = []\n",
            "\n",
            "    for threshold in thresholds:\n",
            "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
            "\n",
            "        if metric == 'f1':\n",
            "            score = f1_score(y_true, y_pred, zero_division=0)\n",
            "        elif metric == 'recall':\n",
            "            score = recall_score(y_true, y_pred, zero_division=0)\n",
            "        elif metric == 'precision':\n",
            "            score = precision_score(y_true, y_pred, zero_division=0)\n",
            "\n",
            "        scores.append(score)\n",
            "\n",
            "    optimal_idx = np.argmax(scores)\n",
            "    return thresholds[optimal_idx], scores[optimal_idx]\n",
            "\n",
            "\n",
            "def calculate_all_metrics(y_true, y_pred_proba, y_pred, threshold, dataset_name=''):\n",
            "    \"\"\"Расчет всех метрик\"\"\"\n",
            "    metrics = {\n",
            "        'dataset': dataset_name,\n",
            "        'threshold': threshold,\n",
            "        'roc_auc': roc_auc_score(y_true, y_pred_proba),\n",
            "        'pr_auc': average_precision_score(y_true, y_pred_proba),\n",
            "        'accuracy': accuracy_score(y_true, y_pred),\n",
            "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
            "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
            "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
            "    }\n",
            "    metrics['gini'] = 2 * metrics['roc_auc'] - 1\n",
            "\n",
            "    cm = confusion_matrix(y_true, y_pred)\n",
            "    metrics['tn'] = cm[0, 0]\n",
            "    metrics['fp'] = cm[0, 1]\n",
            "    metrics['fn'] = cm[1, 0]\n",
            "    metrics['tp'] = cm[1, 1]\n",
            "\n",
            "    return metrics\n",
            "\n",
            "print(\"\\n✓ Helper functions определены\")\n",
            "print(\"  - calculate_psi: PSI расчет\")\n",
            "print(\"  - calculate_decile_table: Метрики по перцентилям\")\n",
            "print(\"  - prepare_data_for_model: Подготовка данных для моделей\")\n",
            "print(\"  - find_optimal_threshold: Оптимальный порог\")\n",
            "print(\"  - calculate_all_metrics: Все метрики\")"
        ]
    },
]

# Добавляем новые ячейки
nb['cells'].extend(new_cells)

# Сохраняем
with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=1, ensure_ascii=False)

print(f"✓ Добавлено {len(new_cells)} ячеек в {notebook_path}")
