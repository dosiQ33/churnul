{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация целевой переменной в двухмерном пространстве\n",
    "\n",
    "## PCA / LDA / NCA\n",
    "\n",
    "Этот notebook демонстрирует три метода снижения размерности для визуализации целевой переменной:\n",
    "\n",
    "1. **PCA (Principal Component Analysis)** - максимизирует дисперсию\n",
    "2. **LDA (Linear Discriminant Analysis)** - максимизирует разделимость классов\n",
    "3. **NCA (Neighborhood Components Analysis)** - оптимизирует kNN классификацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis as NCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Настройки визуализации\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 10000  # Для ускорения (особенно NCA)\n",
    "\n",
    "print(\"✓ Библиотеки загружены\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к данным\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_FILE = DATA_DIR / \"churn_train_ul.parquet\"\n",
    "\n",
    "print(f\"Поиск файла: {TRAIN_FILE}\")\n",
    "\n",
    "# Проверка существования\n",
    "if TRAIN_FILE.exists():\n",
    "    print(f\"✓ Файл найден! Загрузка...\")\n",
    "    df = pd.read_parquet(TRAIN_FILE)\n",
    "    print(f\"✓ Загружено: {df.shape}\")\n",
    "    print(f\"\\nПервые строки:\")\n",
    "    display(df.head())\n",
    "    \n",
    "else:\n",
    "    print(f\"⚠ Файл не найден: {TRAIN_FILE}\")\n",
    "    print(\"\\nСоздание СИНТЕТИЧЕСКИХ данных для демонстрации...\")\n",
    "    \n",
    "    # Синтетические данные\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    n_samples = 5000\n",
    "    n_features = 50\n",
    "    \n",
    "    # Класс 0 (не churn)\n",
    "    X_class0 = np.random.randn(int(n_samples * 0.985), n_features) * 0.8\n",
    "    y_class0 = np.zeros(int(n_samples * 0.985))\n",
    "    \n",
    "    # Класс 1 (churn)\n",
    "    X_class1 = np.random.randn(int(n_samples * 0.015), n_features) * 1.2 + 2\n",
    "    y_class1 = np.ones(int(n_samples * 0.015))\n",
    "    \n",
    "    # Объединение\n",
    "    X = np.vstack([X_class0, X_class1])\n",
    "    y = np.hstack([y_class0, y_class1])\n",
    "    \n",
    "    df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "    df['target_churn_3m'] = y.astype(int)\n",
    "    \n",
    "    print(f\"✓ Создано {len(df):,} синтетических записей\")\n",
    "    print(f\"✓ Признаков: {n_features}\")\n",
    "\n",
    "print(f\"\\nИтоговая размерность: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Целевая переменная и ID колонки\n",
    "TARGET_COL = 'target_churn_3m'\n",
    "ID_COLS = ['cli_code', 'client_id', 'observation_point']\n",
    "\n",
    "# Выбор признаков\n",
    "feature_cols = [col for col in df.columns if col not in ID_COLS + [TARGET_COL]]\n",
    "numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Всего признаков: {len(feature_cols)}\")\n",
    "print(f\"Числовых признаков: {len(numeric_cols)}\")\n",
    "\n",
    "# Создание X и y\n",
    "X = df[numeric_cols].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "# Обработка пропусков\n",
    "if X.isnull().any().any():\n",
    "    print(\"Заполнение пропусков медианой...\")\n",
    "    X = X.fillna(X.median())\n",
    "\n",
    "# Удаление константных признаков\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(f\"Удаление {len(constant_cols)} константных признаков...\")\n",
    "    X = X.drop(columns=constant_cols)\n",
    "\n",
    "print(f\"\\nФинальная размерность: {X.shape}\")\n",
    "print(f\"\\nРаспределение целевой переменной:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nChurn rate: {y.mean():.4f} ({y.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сэмплирование для ускорения (если нужно)\n",
    "if len(X) > SAMPLE_SIZE:\n",
    "    print(f\"Сэмплирование {SAMPLE_SIZE:,} записей для визуализации...\")\n",
    "    X_sample, _, y_sample, _ = train_test_split(\n",
    "        X, y, \n",
    "        train_size=SAMPLE_SIZE, \n",
    "        stratify=y, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    X = X_sample\n",
    "    y = y_sample\n",
    "    print(f\"✓ Выборка: {X.shape}\")\n",
    "\n",
    "# Стандартизация (критично важно!)\n",
    "print(\"\\nСтандартизация признаков...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"✓ Данные стандартизированы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Применение методов снижения размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[PCA] Principal Component Analysis...\")\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_var_pca = pca.explained_variance_ratio_\n",
    "print(f\"✓ Explained variance:\")\n",
    "print(f\"  PC1: {explained_var_pca[0]:.4f} ({explained_var_pca[0]*100:.2f}%)\")\n",
    "print(f\"  PC2: {explained_var_pca[1]:.4f} ({explained_var_pca[1]*100:.2f}%)\")\n",
    "print(f\"  Total: {explained_var_pca.sum():.4f} ({explained_var_pca.sum()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LDA (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[LDA] Linear Discriminant Analysis...\")\n",
    "\n",
    "# LDA для бинарной классификации дает 1 компоненту\n",
    "# Добавляем вторую через PCA для визуализации\n",
    "lda = LDA(n_components=1)\n",
    "X_lda_comp1 = lda.fit_transform(X_scaled, y)\n",
    "\n",
    "# Вторая компонента - PCA\n",
    "pca_for_lda = PCA(n_components=2)\n",
    "X_pca_temp = pca_for_lda.fit_transform(X_scaled)\n",
    "X_lda = np.column_stack([X_lda_comp1, X_pca_temp[:, 1]])\n",
    "\n",
    "print(\"✓ LDA применен (1D discriminant + 1D PCA)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 NCA (Neighborhood Components Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[NCA] Neighborhood Components Analysis...\")\n",
    "print(\"⚠ NCA может занять несколько минут на больших данных...\")\n",
    "\n",
    "# NCA очень медленный - ограничим размер выборки\n",
    "nca = NCA(n_components=2, random_state=RANDOM_STATE, max_iter=100, verbose=0)\n",
    "\n",
    "if len(X_scaled) > 5000:\n",
    "    print(f\"Используем {5000} образцов для NCA...\")\n",
    "    idx_nca = np.random.choice(len(X_scaled), 5000, replace=False)\n",
    "    X_nca = nca.fit_transform(X_scaled[idx_nca], y.iloc[idx_nca])\n",
    "    y_nca = y.iloc[idx_nca]\n",
    "else:\n",
    "    X_nca = nca.fit_transform(X_scaled, y)\n",
    "    y_nca = y\n",
    "\n",
    "print(\"✓ NCA завершен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание фигуры\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Визуализация целевой переменной в двухмерном пространстве', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Цвета\n",
    "colors = ['#2ecc71', '#e74c3c']  # Зеленый для No Churn, Красный для Churn\n",
    "labels = ['No Churn (0)', 'Churn (1)']\n",
    "\n",
    "# --- PCA ---\n",
    "ax = axes[0]\n",
    "for class_val in [0, 1]:\n",
    "    mask = y == class_val\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "              c=colors[class_val],\n",
    "              label=labels[class_val],\n",
    "              alpha=0.6,\n",
    "              s=20,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.3)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({explained_var_pca[0]:.2%} variance)', fontsize=11)\n",
    "ax.set_ylabel(f'PC2 ({explained_var_pca[1]:.2%} variance)', fontsize=11)\n",
    "ax.set_title('PCA\\n(Principal Component Analysis)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- LDA ---\n",
    "ax = axes[1]\n",
    "for class_val in [0, 1]:\n",
    "    mask = y == class_val\n",
    "    ax.scatter(X_lda[mask, 0], X_lda[mask, 1],\n",
    "              c=colors[class_val],\n",
    "              label=labels[class_val],\n",
    "              alpha=0.6,\n",
    "              s=20,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.3)\n",
    "\n",
    "ax.set_xlabel('LD1 (Linear Discriminant)', fontsize=11)\n",
    "ax.set_ylabel('PC1 (PCA Component)', fontsize=11)\n",
    "ax.set_title('LDA\\n(Linear Discriminant Analysis)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- NCA ---\n",
    "ax = axes[2]\n",
    "for class_val in [0, 1]:\n",
    "    mask = y_nca == class_val\n",
    "    ax.scatter(X_nca[mask, 0], X_nca[mask, 1],\n",
    "              c=colors[class_val],\n",
    "              label=labels[class_val],\n",
    "              alpha=0.6,\n",
    "              s=20,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.3)\n",
    "\n",
    "ax.set_xlabel('NCA Component 1', fontsize=11)\n",
    "ax.set_ylabel('NCA Component 2', fontsize=11)\n",
    "ax.set_title('NCA\\n(Neighborhood Components Analysis)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Сохранение\n",
    "output_dir = Path(\"figures\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_file = output_dir / \"target_visualization_pca_lda_nca.png\"\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n✓ Визуализация сохранена: {output_file}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Интерпретация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n[PCA] Principal Component Analysis:\")\n",
    "print(\"  • Несупервизированный метод (не использует метки классов)\")\n",
    "print(\"  • Находит направления максимальной дисперсии\")\n",
    "print(f\"  • Первые 2 компоненты объясняют {explained_var_pca.sum():.2%} дисперсии\")\n",
    "print(\"  • Полезно для понимания общей структуры данных\")\n",
    "\n",
    "print(\"\\n[LDA] Linear Discriminant Analysis:\")\n",
    "print(\"  • Супервизированный метод (использует метки классов)\")\n",
    "print(\"  • Максимизирует разделимость между классами\")\n",
    "print(\"  • Для бинарной классификации: 1 дискриминант + 1 PCA компонента\")\n",
    "print(\"  • Лучше для визуализации разделимости классов\")\n",
    "\n",
    "print(\"\\n[NCA] Neighborhood Components Analysis:\")\n",
    "print(\"  • Супервизированный метод (использует метки классов)\")\n",
    "print(\"  • Оптимизирует метрику для kNN классификации\")\n",
    "print(\"  • Учитывает локальную структуру данных\")\n",
    "print(\"  • Наиболее вычислительно затратный метод\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РЕКОМЕНДАЦИИ:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. PCA - для исследования общей структуры данных\")\n",
    "print(\"2. LDA - для максимальной разделимости классов\")\n",
    "print(\"3. NCA - для учета локальных паттернов и улучшения kNN\")\n",
    "print(\"\\n✓ Анализ завершен!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Дополнительный анализ: Отдельные графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более детальный PCA график\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for class_val in [0, 1]:\n",
    "    mask = y == class_val\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "              c=colors[class_val],\n",
    "              label=labels[class_val],\n",
    "              alpha=0.5,\n",
    "              s=30,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({explained_var_pca[0]:.2%} variance)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({explained_var_pca[1]:.2%} variance)', fontsize=12)\n",
    "ax.set_title('PCA - Детальная визуализация', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', framealpha=0.9, fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"pca_detailed.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более детальный LDA график\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for class_val in [0, 1]:\n",
    "    mask = y == class_val\n",
    "    ax.scatter(X_lda[mask, 0], X_lda[mask, 1],\n",
    "              c=colors[class_val],\n",
    "              label=labels[class_val],\n",
    "              alpha=0.5,\n",
    "              s=30,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('LD1 (Linear Discriminant)', fontsize=12)\n",
    "ax.set_ylabel('PC1 (PCA Component)', fontsize=12)\n",
    "ax.set_title('LDA - Детальная визуализация', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', framealpha=0.9, fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"lda_detailed.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Итоги\n",
    "\n",
    "Мы успешно визуализировали целевую переменную в двухмерном пространстве тремя методами:\n",
    "\n",
    "- **PCA**: Показывает общую структуру данных\n",
    "- **LDA**: Максимизирует разделимость классов\n",
    "- **NCA**: Оптимизирует для kNN классификации\n",
    "\n",
    "Все визуализации сохранены в директории `figures/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
