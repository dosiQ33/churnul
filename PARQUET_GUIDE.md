# üöÄ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Parquet –≤–º–µ—Å—Ç–æ CSV

## –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Parquet?

### –í–∞—à–∏ —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV):
- **–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞**: ~5 GB
- **–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏**: ~60 —Å–µ–∫—É–Ω–¥
- **–ü–∞–º—è—Ç—å**: 5194 MB ‚Üí 2286 MB (–ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
- **–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö**: —Ç–µ—Ä—è—é—Ç—Å—è, –Ω—É–∂–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑

### –° Parquet –±—É–¥–µ—Ç:
- **–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞**: ~800 MB (–≤ 6 —Ä–∞–∑ –º–µ–Ω—å—à–µ! ‚úÖ)
- **–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏**: ~5-10 —Å–µ–∫—É–Ω–¥ (–≤ 10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ! ‚úÖ)
- **–ü–∞–º—è—Ç—å**: ~2286 MB —Å—Ä–∞–∑—É (—É–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ ‚úÖ)
- **–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö**: —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ ‚úÖ

---

## üìã –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV ‚Üí Parquet (–æ–¥–∏–Ω —Ä–∞–∑)

```bash
python csv_to_parquet_converter.py
```

–≠—Ç–æ:
1. –ó–∞–≥—Ä—É–∑–∏—Ç –≤–∞—à–∏ CSV —Ñ–∞–π–ª—ã (—Å delimiter='|', encoding='windows-1251')
2. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö (int8/16/32, float32, category)
3. –°–æ—Ö—Ä–∞–Ω–∏—Ç –≤ Parquet —Å —Å–∂–∞—Ç–∏–µ–º
4. –ü—Ä–æ–≤–µ—Ä–∏—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö

**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è**: ~2-3 –º–∏–Ω—É—Ç—ã (–æ–¥–∏–Ω —Ä–∞–∑!)

---

### –®–∞–≥ 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Parquet –≤ –∫–æ–¥–µ

#### –ë—ã–ª–æ (CSV):
```python
# –ú–µ–¥–ª–µ–Ω–Ω–æ (60 —Å–µ–∫) –∏ –∂—Ä—ë—Ç –ø–∞–º—è—Ç—å
df = pd.read_csv(
    'data/churn_train_ul.csv',
    delimiter='|',
    encoding='windows-1251',
    thousands=',',
    low_memory=False
)
df.columns = df.columns.str.lower().str.strip()

# –ù—É–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∏–ø—ã
df = optimize_dtypes(df)
```

#### –°—Ç–∞–ª–æ (Parquet):
```python
# –ë—ã—Å—Ç—Ä–æ (5 —Å–µ–∫) –∏ —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
df = pd.read_parquet('data/churn_train_ul.parquet')

# –í—Å—ë! –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —É–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã ‚úÖ
```

---

## üîß –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∞—à–µ–≥–æ DataLoader

### –ë—ã–ª–æ:
```python
class DataLoader:
    def load(self, optimize_memory=True):
        df = pd.read_csv(
            self.file_path,
            delimiter=self.delimiter,
            encoding=self.encoding,
            thousands=',',
            low_memory=False
        )

        memory_before = df.memory_usage(deep=True).sum() / 1024**2
        df.columns = df.columns.str.lower().str.strip()

        if optimize_memory:
            df = self._optimize_dtypes(df)

        return df
```

### –°—Ç–∞–ª–æ:
```python
class DataLoader:
    def load(self):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ Parquet –≤–µ—Ä—Å–∏—è
        parquet_path = self.file_path.with_suffix('.parquet')

        if parquet_path.exists():
            # –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Parquet
            df = pd.read_parquet(parquet_path)
            self.logger.info(f"‚úì Loaded from Parquet: {df.shape}")
        else:
            # Fallback –Ω–∞ CSV (–µ—Å–ª–∏ Parquet –Ω–µ—Ç)
            df = pd.read_csv(
                self.file_path,
                delimiter=self.delimiter,
                encoding=self.encoding,
                thousands=',',
                low_memory=False
            )
            df.columns = df.columns.str.lower().str.strip()
            df = self._optimize_dtypes(df)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
            df.to_parquet(parquet_path, compression='snappy')
            self.logger.info(f"‚úì Saved to Parquet: {parquet_path}")

        return df
```

---

## üí° –ü–æ–ª–µ–∑–Ω—ã–µ —Ñ–∏—à–∫–∏ Parquet

### 1. –ß–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (—Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏)
```python
# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ 5 –∫–æ–ª–æ–Ω–æ–∫ –≤–º–µ—Å—Ç–æ 195
columns = ['cli_code', 'target_churn_3m', 'segment_group',
           'avg_activity_6m', 'active_months_6m']

df = pd.read_parquet('data/churn_train_ul.parquet', columns=columns)

# –≠—Ç–æ –°–£–ü–ï–† –±—ã—Å—Ç—Ä–æ! ~1 —Å–µ–∫—É–Ω–¥–∞ –≤–º–µ—Å—Ç–æ 60!
```

### 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ PyArrow)
```python
import pyarrow.parquet as pq

# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
table = pq.read_table('data/churn_train_ul.parquet',
                      filters=[('segment_group', '=', 'SMALL_BUSINESS')])
df = table.to_pandas()
```

### 3. –†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–∂–∞—Ç–∏—è
```python
# –ë—ã—Å—Ç—Ä–æ–µ —Å–∂–∞—Ç–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
df.to_parquet('file.parquet', compression='snappy')

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ (–º–µ–Ω—å—à–µ —Ä–∞–∑–º–µ—Ä, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
df.to_parquet('file.parquet', compression='gzip')

# –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å
df.to_parquet('file.parquet', compression='zstd')
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤

| –§–∞–π–ª | CSV —Ä–∞–∑–º–µ—Ä | Parquet —Ä–∞–∑–º–µ—Ä | –≠–∫–æ–Ω–æ–º–∏—è |
|------|-----------|----------------|----------|
| churn_train_ul | ~5000 MB | ~800 MB | **84%** ‚úÖ |
| churn_prod_ul | ~400 MB | ~70 MB | **82%** ‚úÖ |
| train_processed | ~1500 MB | ~250 MB | **83%** ‚úÖ |

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. **–ü–µ—Ä–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ä–µ–º—è** (~2-3 –º–∏–Ω), –Ω–æ —ç—Ç–æ –æ–¥–∏–Ω —Ä–∞–∑
2. **Parquet —Ñ–∞–π–ª—ã –Ω–µ–ª—å–∑—è —á–∏—Ç–∞—Ç—å –≤ –±–ª–æ–∫–Ω–æ—Ç–µ** (–±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
3. **–ù—É–∂–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pyarrow**: `pip install pyarrow`
4. **–í—Å–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è**, –≤–∫–ª—é—á–∞—è category
5. **–†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ pandas** (>= 0.24)

---

## üéØ –ß–µ–∫-–ª–∏—Å—Ç –º–∏–≥—Ä–∞—Ü–∏–∏

- [ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å pyarrow: `pip install pyarrow`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é: `python csv_to_parquet_converter.py`
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ –≤ `/data/`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å DataLoader (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é `pd.read_parquet()`)
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –ø—É—Ç–∏ –≤ –Ω–æ—É—Ç–±—É–∫–∞—Ö: `.csv` ‚Üí `.parquet`
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö
- [ ] –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ CSV (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç)

---

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞

–ü–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:

```python
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∫–∞
df = pd.read_parquet('data/churn_train_ul.parquet')

# –ü—Ä–æ–≤–µ—Ä–∫–∏
print(f"Shape: {df.shape}")  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å (3243871, 195)
print(f"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")  # ~2286 MB

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
for col in ['segment_group', 'obs_month', 'obs_quarter']:
    print(f"{col}: {df[col].dtype} (unique={df[col].nunique()})")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ target
print(f"Target churn rate: {df['target_churn_3m'].mean():.4f}")  # 0.0150
```

---

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É: `pip install pyarrow pandas`
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã: `python example_usage.py`
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏

---

## üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç

–ü–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ Parquet:
- ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ **10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ**
- ‚úÖ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤ –≤ **6 —Ä–∞–∑ –º–µ–Ω—å—à–µ**
- ‚úÖ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- ‚úÖ –ü–∞–º—è—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑ –∫–æ—Ä–æ–±–∫–∏
- ‚úÖ –ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
- ‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ –≤—Å–µ–º–∏ ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏

**–í–∞—à pipeline —Å—Ç–∞–Ω–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ! üöÄ**
