# Визуализация целевой переменной: PCA / LDA / NCA

## Описание

Этот проект содержит инструменты для визуализации целевой переменной (churn) в двухмерном пространстве с использованием трех методов снижения размерности:

1. **PCA (Principal Component Analysis)** - несупервизированный метод, максимизирует дисперсию
2. **LDA (Linear Discriminant Analysis)** - супервизированный метод, максимизирует разделимость классов
3. **NCA (Neighborhood Components Analysis)** - супервизированный метод, оптимизирует kNN классификацию

## Файлы проекта

- `visualize_target_pca_lda_nca.py` - Python скрипт для запуска из командной строки
- `PCA_LDA_NCA_Visualization.ipynb` - Jupyter notebook для интерактивной работы
- `figures/target_visualization_pca_lda_nca.png` - результат визуализации

## Установка зависимостей

```bash
pip install numpy pandas matplotlib seaborn scikit-learn
```

Или если у вас есть `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Использование

### Вариант 1: Python скрипт

```bash
python visualize_target_pca_lda_nca.py
```

Скрипт автоматически:
- Загружает данные из `data/churn_train_ul.parquet`
- Если файл не найден, создает синтетические данные для демонстрации
- Применяет все три метода снижения размерности
- Сохраняет результат в `figures/target_visualization_pca_lda_nca.png`

### Вариант 2: Jupyter Notebook

```bash
jupyter notebook PCA_LDA_NCA_Visualization.ipynb
```

Notebook позволяет:
- Пошагово выполнять анализ
- Визуализировать промежуточные результаты
- Экспериментировать с параметрами
- Создавать дополнительные графики

## Результаты

### PCA (Principal Component Analysis)
- **Характеристика**: Несупервизированный метод
- **Цель**: Находит направления максимальной дисперсии
- **Применение**: Исследование общей структуры данных
- **Преимущество**: Быстрый, простой в интерпретации
- **Недостаток**: Не учитывает метки классов

### LDA (Linear Discriminant Analysis)
- **Характеристика**: Супервизированный метод
- **Цель**: Максимизирует разделимость между классами
- **Применение**: Визуализация разделимости классов
- **Преимущество**: Оптимален для задач классификации
- **Недостаток**: Для бинарной классификации дает только 1 компоненту

### NCA (Neighborhood Components Analysis)
- **Характеристика**: Супервизированный метод
- **Цель**: Оптимизирует метрику для kNN
- **Применение**: Учет локальных паттернов данных
- **Преимущество**: Хорошо работает с локальными структурами
- **Недостаток**: Очень медленный, требует много памяти

## Интерпретация результатов

### Что смотреть на графиках:

1. **Разделимость классов**: Насколько хорошо разделены зеленые (No Churn) и красные (Churn) точки?

2. **Кластеризация**: Образуют ли точки одного класса компактные кластеры?

3. **Перекрытие**: Есть ли области, где классы перекрываются?

4. **Выбросы**: Есть ли изолированные точки вдали от основных кластеров?

### Сравнение методов:

- **PCA** покажет общую структуру данных без учета меток
- **LDA** максимально разделит классы (лучше всего для визуализации разделимости)
- **NCA** учтет локальные паттерны (может показать неочевидные структуры)

## Настройка параметров

В скрипте можно изменить:

```python
RANDOM_STATE = 42          # Для воспроизводимости
SAMPLE_SIZE = 10000        # Размер выборки (для ускорения)
```

В NCA можно настроить:
```python
NCA(
    n_components=2,
    random_state=42,
    max_iter=100,          # Количество итераций
    verbose=0              # Вывод процесса обучения
)
```

## Структура данных

Скрипт ожидает данные в формате:

- **Путь**: `data/churn_train_ul.parquet`
- **Целевая переменная**: `target_churn_3m` (0/1)
- **ID колонки**: `cli_code`, `client_id`, `observation_point` (игнорируются)
- **Признаки**: Все числовые колонки

## Производительность

- **PCA**: Очень быстро (~секунды на 10K записей)
- **LDA**: Быстро (~секунды на 10K записей)
- **NCA**: Медленно (~минуты на 5K записей)

**Рекомендация**: Для больших датасетов используйте сэмплирование.

## Примеры выходных данных

```
================================================================================
ВИЗУАЛИЗАЦИЯ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ: PCA / LDA / NCA
================================================================================

1. Загрузка данных...
  ✓ Загружено: (3243871, 195)

2. Подготовка данных...
  Финальная размерность: (10000, 109)
  Целевая переменная:
    Класс 0 (No Churn): 9,850 (98.50%)
    Класс 1 (Churn):    150 (1.50%)

3. Применение методов снижения размерности...
  [PCA] Explained variance: 12.25%
  [LDA] ✓ Completed
  [NCA] ✓ Completed

4. Создание визуализации...
  ✓ Визуализация сохранена: figures/target_visualization_pca_lda_nca.png

✓ Визуализация завершена успешно!
```

## Устранение проблем

### Проблема: Файл данных не найден
**Решение**: Скрипт автоматически создаст синтетические данные для демонстрации

### Проблема: NCA работает слишком долго
**Решение**: Уменьшите размер выборки или `max_iter` в параметрах NCA

### Проблема: Недостаточно памяти
**Решение**: Уменьшите `SAMPLE_SIZE` в начале скрипта

### Проблема: Ошибка импорта модулей
**Решение**: Установите все зависимости: `pip install numpy pandas matplotlib seaborn scikit-learn`

## Дальнейшие улучшения

Возможные расширения:

1. **3D визуализация**: Добавить интерактивные 3D графики
2. **t-SNE и UMAP**: Добавить другие методы снижения размерности
3. **Плотность вероятности**: Добавить контуры плотности для каждого класса
4. **Сравнение по сегментам**: Отдельная визуализация для разных сегментов клиентов
5. **Интерактивность**: Добавить Plotly для интерактивных графиков

## Авторы

Создано для проекта анализа оттока клиентов банка (Churn Prediction)

## Лицензия

MIT License
